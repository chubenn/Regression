---
title: "Lab 2"
author: "Ben Chu"
date: "January 30, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE, dpi = 300)
```

###Loading in packages
```{r warning = FALSE, message = FALSE}
library(tidyverse)
library(car)
library(QuantPsyc)
library(stats)
library(lmSupport)
```

####Creating the dataset
```{r}
student <- seq(1:12)
exam <- c(100,72,84,41,69,74,95,94,81,83,65,61)
attend <- c(13,15,10,5,9,9,12,9,10,11,2,8)
gpa <- c(3.4,3.9,3.4,2.3,3.0,2.6,4.0,3.9,2.9,3.4,2.2,3.8)
class <- data.frame (student,exam,attend,gpa)
```

##Q1a
```{r}
attendgpa <-lm(exam~attend, data = class)
summary(attendgpa)
```
I would tell the professor that attendence significantly predicts exam scores *R*^2^ = 0.3732, *F*(1,10) = 5.95, *p* <.05

##Q1b
```{r}
examgpa <- lm(exam~gpa, data = class)
summary(examgpa)
```
I would tell the professor that GPA scores significantly predicts exam scores *R*^2^ = 0.3389, *F*(1,10) = 5.125, *p* <.05

##Q1c
```{r}
examscoresattend <- lm(exam~gpa+attend, data = class)
summary(examscoresattend)
```
I would tell the professors that GPA scores with attendence do not significantly predict exam scores *R*^2^ = 0.4126, *F*(2,9) = 3.16, *p* = 0.09

##Q1d
```{r}
cor.test(class$gpa,class$attend)
```
* The instructor is referring to a multiple regression.
* The contradiction exists because the model now consists of multiple predictor values, which if correlated may deflate the *r*^2^ value

##Q1e
```{r}
new.dat = data.frame(attend = 0, gpa = 2.0)
badgrade <- predict(examscoresattend,new.dat)
```
### The student who does not go to class and has a gpa of 2.0 would receive a `r round(badgrade)`

##Q2
###Loading data
```{r}
load("C:/Users/Branly Mclanbry/Downloads/lab2AA.RData")
```
renaming and cleaning data
```{r warning=FALSE}
clean_dat <- lab2AA %>%
 mutate(
   p_agree = q1agree,
   p_fair = q1fair,
   p_eff = q1eff,
   education = q4,
   employment = q5,
   happiness = q7,
   job_choice = q8,
   job_satis = q9,
   ethnicity = qa,
   aa_support = (p_agree + p_fair + p_eff))%>%
  na.omit()
```
###General linear model with all variables
```{r}
every.mod <- lm(aa_support ~ education + employment + happiness + job_choice + job_satis, dat = clean_dat)
summary(every.mod)
lm.beta(every.mod)
```
###Cleaning across racial lines
```{r}
white <- clean_dat %>% 
  filter(ethnicity == "White") %>%
  na.omit()
         
minority <- clean_dat %>%
  filter(ethnicity != "White")
```
##Running series of linear models
```{r}
white.1 <- lm(aa_support ~ education + employment, dat = white)
white.2 <- lm(aa_support ~ education + employment + happiness + job_choice + job_satis, dat = white)
minority.1 <- lm(aa_support ~ education + employment, dat = minority)
minority.2 <- lm(aa_support ~ education + employment + happiness + job_choice + job_satis, dat = minority)
```
###Let's take a look at all the models and some standardized units _b_*
```{r}
summary(white.1)
lm.beta(white.1)
summary(white.2)
lm.beta(white.2)
summary(minority.1)
lm.beta(minority.1)
summary(minority.2)
lm.beta(minority.2)
```
The writes up suggest that for white participants, affirmitave action is supported multiple variables *R*^2^ = 0.14, *F*(2,173) = 14.29, *p* <.05. Although, not all variables contributed to the prediction. Greater education (_b_* = .45, *p* < .05) related to  more support for affirmative action. Employment did not relate to affirmative action (_b_* = -.10, *p* = .50)

For minority participants, affirmitave action is supported multiple variables *R*^2^ = 0.22, *F*(2,161) = 23, *p* <.05. Although, not all variables contributed to the prediction. Greater employment (_b_* = .40, *p* < .05) related to  more support for affirmative action. Education did not relate to affirmative action (_b_* = .10, *p* = .29)

##Lastly, comparison of models against each other.
```{r eval = FALSE}
anova(minority.1,minority.2)
anova(white.1,white.2)
```
I like to use `modelCompare`
```{r}
modelCompare(minority.1,minority.2)
modelCompare(white.1,white.2)
```

Looking at the hierarchical multiple regression, we find that the _R_^2^ change = `r round(summary(white.2)$r.squared - summary(white.1)$r.squared,2)`, *p* < .05 for white participants. For minorities, the _R_^2^ change = `r  round(summary(minority.2)$r.squared - summary(minority.1)$r.squared,2)`,*p*  < .05

##Semi-partial correlations

### Here is the formula that is used.
```{r eval = FALSE}
values <-summary(white.2)
r2 <- values$r.squared[1]
dfr<-values$df[2]
dfr
values <-summary(white.2)
r2 <- values$r.squared[1]
dfr<-values$df[2]
t1 <- values$coefficients[2,3]
t2 <- values$coefficients[3,3]
t3 <- values$coefficients[4,3]
t4 <- values$coefficients[5,3]
t5 <- values$coefficients[6,3]
sr1<-((t1^2)/dfr)*(1-r2)
sr2<-((t2^2)/dfr)*(1-r2)
sr3<-((t3^2)/dfr)*(1-r2)
sr4<-((t4^2)/dfr)*(1-r2)
sr5<-((t5^2)/dfr)*(1-r2)
```
Here is the `modelEffectSizes`. 
```{r}
modelEffectSizes(white.2)
modelEffectSizes(minority.2)
```

```{r}
lm.describeData(white)
```