knitr::opts_chunk$set(cache = TRUE, dpi = 300)
anova(minority.1,minority.2)
---
title: "Lab 2"
author: "Ben Chu"
date: "January 30, 2018"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE, dpi = 300)
```
###Loading in packages
```{r warning = FALSE, message = FALSE}
library(tidyverse)
library(car)
library(QuantPsyc)
library(stats)
library(papaja)
```
####Creating the dataset
```{r}
student <- seq(1:12)
exam <- c(100,72,84,41,69,74,95,94,81,83,65,61)
attend <- c(13,15,10,5,9,9,12,9,10,11,2,8)
gpa <- c(3.4,3.9,3.4,2.3,3.0,2.6,4.0,3.9,2.9,3.4,2.2,3.8)
class <- data.frame (student,exam,attend,gpa)
```
##Q1a
```{r}
attendgpa <-lm(exam~attend, data = class)
summary(attendgpa)
```
I would tell the professor that attendence significantly predicts exam scores *R*^2^ = 0.3732, *F*(1,10) = 5.95, *p* <.05
##Q1b
```{r}
examgpa <- lm(exam~gpa, data = class)
summary(examgpa)
```
I would tell the professor that GPA scores significantly predicts exam scores *R*^2^ = 0.3389, *F*(1,10) = 5.125, *p* <.05
##Q1c
```{r}
examscoresattend <- lm(exam~gpa+attend, data = class)
summary(examscoresattend)
```
I would tell the professors that GPA scores with attendence do not significantly predict exam scores *R*^2^ = 0.4126, *F*(2,9) = 3.16, *p* = 0.09
##Q1d
```{r}
cor.test(class$gpa,class$attend)
```
* The instructor is referring to a multiple regression.
* The contradiction exists because the model now consists of multiple predictor values, which if correlated may deflate the *r*^2^ value
##Q1e
```{r}
new.dat = data.frame(attend = 0, gpa = 2.0)
badgrade <- predict(examscoresattend,new.dat)
```
### The student who does not go to class and has a gpa of 2.0 would receive a `r round(badgrade)`
##Q2
###Loading data
```{r}
load("C:/Users/Branly Mclanbry/Downloads/lab2AA.RData")
```
renaming and cleaning data
```{r warning=FALSE}
clean_dat <- lab2AA %>%
mutate(
p_agree = q1agree,
p_fair = q1fair,
p_eff = q1eff,
education = q4,
employment = q5,
happiness = q7,
job_choice = q8,
job_satis = q9,
ethnicity = qa,
aa_support = (p_agree + p_fair + p_eff))%>%
na.omit()
```
###General linear model with all variables
```{r}
every.mod <- lm(aa_support ~ education + employment + happiness + job_choice + job_satis, dat = clean_dat)
summary(every.mod)
lm.beta(every.mod)
```
###Cleaning across racial lines
```{r}
white <- clean_dat %>%
filter(ethnicity == "White") %>%
na.omit()
minority <- clean_dat %>%
filter(ethnicity != "White")
```
##Running series of linear models
```{r}
white.1 <- lm(aa_support ~ education + employment, dat = white)
white.2 <- lm(aa_support ~ education + employment + happiness + job_choice + job_satis, dat = white)
minority.1 <- lm(aa_support ~ education + employment, dat = minority)
minority.2 <- lm(aa_support ~ education + employment + happiness + job_choice + job_satis, dat = minority)
```
###Let's take a look at all the models and some standardized units _b_*
```{r}
summary(white.1)
lm.beta(white.1)
summary(white.2)
lm.beta(white.2)
summary(minority.1)
lm.beta(minority.1)
summary(minority.2)
lm.beta(minority.2)
```
The writes up suggest that for white participants, affirmitave action is supported multiple variables *R*^2^ = 0.14, *F*(2,173) = 14.29, *p* <.05. Although, not all variables contributed to the prediction. Greater education (_b_* = .45, *p* < .05) related to  more support for affirmative action. Employment did not relate to affirmative action (_b_* = -.10, *p* = .50)
For minority participants, affirmitave action is supported multiple variables *R*^2^ = 0.22, *F*(2,161) = 23, *p* <.05. Although, not all variables contributed to the prediction. Greater employment (_b_* = .40, *p* < .05) related to  more support for affirmative action. Education did not relate to affirmative action (_b_* = .10, *p* = .29)
##Lastly, comparison of models against each other.
```{r}
anova(minority.1,minority.2)
anova(white.1,white.2)
```
Looking at the hierarchical multiple regression, we find that the _R_^2^ change = {r }
white.1$residuals
white.1$terms
white.1$df.residual
white.1$qr
white.1$assign
white.1$coefficients
white.1$residuals
white.1$effects
white.1$fitted.values
white.1$effects
white.1$assign
white.1$qr
white.1$df.residual
white.1$xlevels
white.1$call
white.1$terms
white.1$
white.1$model
summary(white.1)
white.1$residuals
white.1$r.squared
summary(white.1)$r.squared
summary(white.1)
summary(white.1)
summary(white.2)
summary(white.2)$r.squared - summary(white.2)$r.squared
summary(minority.1)
summary(minority.2)
summary(minority.2)$r.squared - summary(minority.1)$r.squared
library(ppcor)
install.packages("ppcor")
install.packages("ppcor")
library(ppcor)
spcor(white.2)
spcor(white)
View(white)
white.cor <- white %>%
select(education , employment , happiness , job_choice , job_satis)
white.cor <- white %>%
select(education , employment , happiness , job_choice , job_satis)
View(white)
View(white)
white.cor <- white %>%
select(education , employment , happiness , job_choice , job_satis)
white.cor <- white %>%
select(education,employment,happiness,job_choice,job_satis)
list(white)
names(white)
white.cor <- white %>%
select(education)
white.cor <- white %>% select(education)
white.cor <- white
white.cor <- white %>% select(q1)
View(white)
View(white)
white.cor <- white %>% select(q8)
white.cor <- white %>%
dplyr::select(education , employment , happiness , job_choice , job_satis)
spcor(white.cor)
View(lab2AA)
View(lab2AA)
spcor.test(white.cor)
spcor(white.cor)
lab2AA$support <- lab2AA$q1agree + lab2AA$q1fair + lab2AA$q1eff
ANWModel.1<-lm(formula = support ~ q7 + q8 + q9, data = nonwhite)
summary (ANWModel.1) #Prints analysis for abstract nonwhite
ANWModel.1<-lm(formula = support ~ q7 + q8 + q9, data = nonwhite)
summary(white.1)
summary(white.2)
round(summary(white.2)$r.squared - summary(white.1)$r.squared,2)
round(summary(white.2)$r.squared - summary(white.1)$r.squared,2)
values <-summary(white.2)
r2 <- values$r.squared[1]
dfr<-values$df[2]
dfr
values <-summary(white.2)
r2 <- values$r.squared[1]
dfr<-values$df[2]
t1 <- values$coefficients[2,3]
t2 <- values$coefficients[3,3]
t3 <- values$coefficients[4,3]
t4 <- values$coefficients[5,3]
t5 <- values$coefficients[6,3]
sr1<-((t1^2)/dfr)*(1-r2)
sr2<-((t1^2)/dfr)*(2-r2)
sr3<-((t1^2)/dfr)*(3-r2)
sr4<-((t1^2)/dfr)*(4-r2)
sr5<-((t1^2)/dfr)*(5-r2)
sr1
sr2
sr3
sr4
sr5
white.cor <- white %>%
dplyr::select(education , employment , happiness , job_choice , job_satis)
spcor(white.cor)
cor_lm <- function(white.2) {
dv <- names(white.2$model)[1]
dv_data <- white.2$model[, dv]
ivs <- names(white.2$model)[-1]
iv_data <- white.2$model[, ivs]
x <- white.2$model
x_omit <- lapply(ivs, function(X) x[, c(dv, setdiff(ivs, X))])
names(x_omit) <- ivs
lapply(x_omit, head)
fits_omit <- lapply(x_omit, function(X) lm(as.formula(paste(dv, "~ .")),
data = X))
resid_omit <- sapply(fits_omit, resid)
iv_omit <- lapply(ivs, function(X) lm(as.formula(paste(X, "~ .")), data = iv_data))
resid_iv_omit <- sapply(iv_omit, resid)
results <- sapply(seq(ivs), function(i) c(zeroorder = cor(iv_data[, i],
dv_data), partial = cor(resid_iv_omit[, i], resid_omit[, i]), semipartial = cor(resid_iv_omit[,
i], dv_data)))
results <- data.frame(results)
names(results) <- ivs
results <- data.frame(t(results))
results
}
cor_lm(white.2)
cor_lm <- function(semipartial) {
dv <- names(semipartial$model)[1]
dv_data <- semipartial$model[, dv]
ivs <- names(semipartial$model)[-1]
iv_data <- semipartial$model[, ivs]
x <- semipartial$model
x_omit <- lapply(ivs, function(X) x[, c(dv, setdiff(ivs, X))])
names(x_omit) <- ivs
lapply(x_omit, head)
fits_omit <- lapply(x_omit, function(X) lm(as.formula(paste(dv, "~ .")),
data = X))
resid_omit <- sapply(fits_omit, resid)
iv_omit <- lapply(ivs, function(X) lm(as.formula(paste(X, "~ .")), data = iv_data))
resid_iv_omit <- sapply(iv_omit, resid)
results <- sapply(seq(ivs), function(i) c(zeroorder = cor(iv_data[, i],
dv_data), partial = cor(resid_iv_omit[, i], resid_omit[, i]), semipartial = cor(resid_iv_omit[,
i], dv_data)))
results <- data.frame(results)
names(results) <- ivs
results <- data.frame(t(results))
results
}
cor_lm(white.2)
values <-summary(white.2)
r2 <- values$r.squared[1]
dfr<-values$df[2]
dfr
values <-summary(white.2)
r2 <- values$r.squared[1]
dfr<-values$df[2]
t1 <- values$coefficients[2,3]
t2 <- values$coefficients[3,3]
t3 <- values$coefficients[4,3]
t4 <- values$coefficients[5,3]
t5 <- values$coefficients[6,3]
sr1<-((t1^2)/dfr)*(1-r2)
sr2<-((t1^2)/dfr)*(2-r2)
sr3<-((t1^2)/dfr)*(3-r2)
sr4<-((t1^2)/dfr)*(4-r2)
sr5<-((t1^2)/dfr)*(5-r2)
sr1
sr2
sr3
sr4
sr5
install.packages("lmSupport")
lm.sumSquares(white.2)
library("lmSupport", lib.loc="~/R/win-library/3.3")
lm.sumSquares(white.2)
values <-summary(white.2)
r2 <- values$r.squared[1]
dfr<-values$df[2]
dfr
values <-summary(white.2)
r2 <- values$r.squared[1]
dfr<-values$df[2]
t1 <- values$coefficients[2,3]
t2 <- values$coefficients[3,3]
t3 <- values$coefficients[4,3]
t4 <- values$coefficients[5,3]
t5 <- values$coefficients[6,3]
sr1<-((t1^2)/dfr)*(1-r2)
sr2<-((t1^2)/dfr)*(2-r2)
sr3<-((t1^2)/dfr)*(3-r2)
sr4<-((t1^2)/dfr)*(4-r2)
sr5<-((t1^2)/dfr)*(5-r2)
sr1
sr2
sr3
sr4
sr5
lm.sumSquares(white.2)
round(lm.sumSquares(white.2),2)
round(lm.sumSquares(white.2),2)
round(lm.sumSquares(white.2))
(lm.sumSquares(white.2)
lm.sumSquares(white.2)
lm.sumSquares(white.2)
cor_lm(white.2)
lm.sumSquares(white.2)
modelEffectSizes(white.2)
t1
sr1<-((t1^2)/dfr)*(1-r2)
t1 <- values$coefficients[2,3]
t2 <- values$coefficients[3,3]
t3 <- values$coefficients[4,3]
t4 <- values$coefficients[5,3]
t5 <- values$coefficients[6,3]
sr1<-((t1^2)/dfr)*(1-r2)
sr2<-((t2^2)/dfr)*(2-r2)
sr3<-((t3^2)/dfr)*(3-r2)
sr4<-((t4^2)/dfr)*(4-r2)
sr5<-((t5^2)/dfr)*(5-r2)
sr1
sr2
sr3
sr4
sr5
modelEffectSizes(white.2)
sr1<-((t1^2)/dfr)*(1-r2)
sr2<-((t2^2)/dfr)*(1-r2)
sr3<-((t3^2)/dfr)*(1-r2)
sr4<-((t4^2)/dfr)*(1-r2)
sr5<-((t5^2)/dfr)*(1-r2)
sr1
sr2
sr3
sr4
sr5
modelEffectSizes(white.2)
sr1
education + employment + happiness + job_choice + job_satis
sr2
sr3
sr4
sr4
sr5
modelEffectSizes(white.2)
cor_lm <- function(semipartial) {
dv <- names(semipartial$model)[1]
dv_data <- semipartial$model[, dv]
ivs <- names(semipartial$model)[-1]
iv_data <- semipartial$model[, ivs]
x <- semipartial$model
x_omit <- lapply(ivs, function(X) x[, c(dv, setdiff(ivs, X))])
names(x_omit) <- ivs
lapply(x_omit, head)
fits_omit <- lapply(x_omit, function(X) lm(as.formula(paste(dv, "~ .")),
data = X))
resid_omit <- sapply(fits_omit, resid)
iv_omit <- lapply(ivs, function(X) lm(as.formula(paste(X, "~ .")), data = iv_data))
resid_iv_omit <- sapply(iv_omit, resid)
results <- sapply(seq(ivs), function(i) c(zeroorder = cor(iv_data[, i],
dv_data), partial = cor(resid_iv_omit[, i], resid_omit[, i]), semipartial = cor(resid_iv_omit[,
i], dv_data)))
results <- data.frame(results)
names(results) <- ivs
results <- data.frame(t(results))
results
}
cor_lm(white.2)
modelEffectSizes(white.2)
cor_lm <- function(semipartial) {
dv <- names(semipartial$model)[1]
dv_data <- semipartial$model[, dv]
ivs <- names(semipartial$model)[-1]
iv_data <- semipartial$model[, ivs]
x <- semipartial$model
x_omit <- lapply(ivs, function(X) x[, c(dv, setdiff(ivs, X))])
names(x_omit) <- ivs
lapply(x_omit, head)
fits_omit <- lapply(x_omit, function(X) lm(as.formula(paste(dv, "~ .")),
data = X))
resid_omit <- sapply(fits_omit, resid)
iv_omit <- lapply(ivs, function(X) lm(as.formula(paste(X, "~ .")), data = iv_data))
resid_iv_omit <- sapply(iv_omit, resid)
results <- sapply(seq(ivs), function(i) c(zeroorder = cor(iv_data[, i],
dv_data), partial = cor(resid_iv_omit[, i], resid_omit[, i]), semipartial = cor(resid_iv_omit[,
i], dv_data)))
results <- data.frame(results)
names(results) <- ivs
results <- data.frame(t(results))
results
}
cor_lm(white.2)
(
modelEffectSizes(white.2)
modelEffectSizes(white.2)
modelEffectSizes(white.2)
??lm.beta
lm.detaR2(white.1,white.2)
modelEffectSizes(white.2)
modelEffectSizes(minority.2)
??lm.deltaR2
modelCompare(white.1,white.2)
anova(minority.1,minority.2)
anova(white.1,white.2)
lm.describeData(white)
varDescribe(white, detail = 3)
varDescribe(white, detail = 3)
varDescribe(white, Detail = 3)
varDescribe(white, Detail = 3)
descriptives <- white %>%
summary(
Mean = Mean(employment)
)
apa_table(descriptives)
predictor <- c("Education","Employment","Happiness","R-square change")
range <-c("1-7","1-7","1-7","")
test <- data.frame(predictor,range)
kable(test)
??kable
modelCompare(minority.1,minority.2)
modelCompare(white.1,white.2)
